{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce5134f",
   "metadata": {},
   "source": [
    "# üé• **04-Inferencia de Video con YOLO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b284f",
   "metadata": {},
   "source": [
    "Este notebook aplica un modelo YOLO entrenado (o pre-entrenado) para detectar y contar veh√≠culos en un video, guardar la secuencia anotada y reportar m√©tricas de rendimiento (FPS, latencia, tiempo total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cc0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac81ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video de entrada \n",
    "VIDEO_IN = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/data/test/Bogot√° traffic video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ddf301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos del modelo YOLO entrenado \n",
    "MODEL_PT = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/models/yolov10m/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67059557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caperta de salida para los resultados\n",
    "OUTPUT_DIR = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b607f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video de salida con las detecciones\n",
    "VIDEO_OUT = OUTPUT_DIR / f\"{VIDEO_IN.stem}_yolo_test.mp4\"\n",
    "# Otros par√°metros\n",
    "IMG_SIZE = 640\n",
    "CONF_THRESH = 0.25\n",
    "DEVICE = 0            # 0 ‚Üí GPU 0,  \n",
    "SHOW_FRAMES = False   # True para ver frames en tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e2053a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10m summary (fused): 369 layers, 16,451,542 parameters, 0 gradients, 63.4 GFLOPs\n",
      "Modelo best.pt\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(str(MODEL_PT))\n",
    "model.fuse()  # acelera inferencia\n",
    "print(f\"Modelo {MODEL_PT.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b325a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resoluci√≥n: 360√ó640  |  FPS original: 30.00\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(str(VIDEO_IN))\n",
    "assert cap.isOpened(), f\"No se pudo abrir {VIDEO_IN}\"\n",
    "\n",
    "# Propiedades del video\n",
    "fps_in  = cap.get(cv2.CAP_PROP_FPS)\n",
    "width   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Resoluci√≥n: {width}√ó{height}  |  FPS original: {fps_in:.2f}\")\n",
    "\n",
    "# üé• VideoWriter para guardar la salida\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") # type: ignore\n",
    "writer = cv2.VideoWriter(str(VIDEO_OUT), fourcc, fps_in, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1925088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Inferencia y escritura de frames\n",
    "frame_count, t0 = 0, time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Inferencia\n",
    "    res = model.predict(\n",
    "        frame,\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=CONF_THRESH,\n",
    "        device=DEVICE,\n",
    "        stream=False,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    # Dibujar resultados sobre el frame\n",
    "    annotated = res.plot()\n",
    "\n",
    "    # Escribir frame anotado\n",
    "    writer.write(annotated)\n",
    "\n",
    "    # Mostrar en pantalla opcional\n",
    "    if SHOW_FRAMES:\n",
    "        cv2.imshow(\"YOLO Inference\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:   # ESC para salir\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "t_total = time.time() - t0\n",
    "cap.release()\n",
    "writer.release()\n",
    "if SHOW_FRAMES:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c441dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà  Frames procesados : 688\n",
      "‚è±Ô∏è  Tiempo total      : 3.21 s\n",
      "‚ö° FPS promedio       : 214.15\n",
      "‚åõ Latencia promedio  : 4.67 ms por frame\n",
      "üéûÔ∏è  Video guardado en : /home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/Bogot√° traffic video_yolo_test.mp4\n"
     ]
    }
   ],
   "source": [
    "fps_real = frame_count / t_total\n",
    "lat_ms   = 1000 * t_total / frame_count\n",
    "\n",
    "print(f\"üìà  Frames procesados : {frame_count}\")\n",
    "print(f\"‚è±Ô∏è  Tiempo total      : {t_total:.2f} s\")\n",
    "print(f\"‚ö° FPS promedio       : {fps_real:.2f}\")\n",
    "print(f\"‚åõ Latencia promedio  : {lat_ms:.2f} ms por frame\")\n",
    "print(f\"üéûÔ∏è  Video guardado en : {VIDEO_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bf88ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10m summary (fused): 369 layers, 16,451,542 parameters, 0 gradients, 63.4 GFLOPs\n",
      "Modelo best.pt\n",
      "‚úÖ Video generado con 18 autos contados\n",
      "üìç Guardado en: /home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/Bogot√° traffic video_count.mp4\n"
     ]
    }
   ],
   "source": [
    "# Rutas y par√°metros\n",
    "VIDEO_IN   = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/data/test/Bogot√° traffic video.mp4\")\n",
    "MODEL_PT   = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/models/yolov10m/weights/best.pt\")\n",
    "OUTPUT_DIR = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VIDEO_OUT  = OUTPUT_DIR / f\"{VIDEO_IN.stem}_count.mp4\"\n",
    "\n",
    "IMG_SIZE    = 640\n",
    "CONF_THRESH = 0.25\n",
    "DEVICE      = 0\n",
    "SHOW_FRAMES = False\n",
    "TRACKER_YAML= \"bytetrack.yaml\"\n",
    "\n",
    "# Cargar modelo\n",
    "model = YOLO(str(MODEL_PT))\n",
    "model.fuse()\n",
    "print(f\"Modelo {MODEL_PT.name}\")\n",
    "car_id = next(i for i, n in model.names.items() if n.lower() == \"car\")\n",
    "\n",
    "# Video de entrada / salida\n",
    "cap = cv2.VideoCapture(str(VIDEO_IN))\n",
    "assert cap.isOpened(), f\"No se pudo abrir {VIDEO_IN}\"\n",
    "\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS)\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "writer = cv2.VideoWriter(str(VIDEO_OUT), cv2.VideoWriter_fourcc(*\"mp4v\"), fps_in, (W, H)) # type: ignore\n",
    "\n",
    "# L√≠nea de cruce\n",
    "line_y = int(0.5 * H)\n",
    "pt1, pt2 = (0, line_y), (W, line_y)\n",
    "\n",
    "# Conteo\n",
    "track_last_pos = {}\n",
    "counted_ids = set()\n",
    "total_cars = 0\n",
    "frame_count, t0 = 0, time.time()\n",
    "\n",
    "# Altura del recuadro superior (en p√≠xeles)\n",
    "box_h = 60\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=CONF_THRESH,\n",
    "        device=DEVICE,\n",
    "        persist=True,\n",
    "        tracker=TRACKER_YAML,\n",
    "        classes=[car_id],\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    annotated = results.plot()\n",
    "\n",
    "    # L√≠nea de cruce\n",
    "    cv2.line(annotated, pt1, pt2, color=(0, 255, 255), thickness=2)\n",
    "\n",
    "    for box, tid in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.id.cpu().numpy()): # type: ignore\n",
    "        tid = int(tid)\n",
    "        x1, y1, x2, y2 = box\n",
    "        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "\n",
    "        prev_cy = track_last_pos.get(tid, cy)\n",
    "        track_last_pos[tid] = cy\n",
    "\n",
    "        if prev_cy < line_y <= cy and tid not in counted_ids:\n",
    "            total_cars += 1\n",
    "            counted_ids.add(tid)\n",
    "\n",
    "        cv2.circle(annotated, (cx, cy), 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Dibujar recuadro amarillo en la parte superior\n",
    "    cv2.rectangle(annotated, (0, 0), (W, box_h), (0, 255, 255), thickness=-1)\n",
    "\n",
    "    # Texto en negro\n",
    "    cv2.putText(annotated, f\"Vehiculos contados: {total_cars}\",\n",
    "                org=(20, int(box_h * 0.7)),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=1.2,\n",
    "                color=(0, 0, 0), thickness=3)\n",
    "\n",
    "    writer.write(annotated)\n",
    "\n",
    "    if SHOW_FRAMES:\n",
    "        cv2.imshow(\"Conteo Vehicular\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Cierre\n",
    "cap.release(); writer.release()\n",
    "if SHOW_FRAMES:\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "t_total = time.time() - t0\n",
    "print(f\"‚úÖ Video generado con {total_cars} autos contados\")\n",
    "print(f\"üìç Guardado en: {VIDEO_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0825a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF creado en: /home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/Bogot√° traffic video_count.gif\n"
     ]
    }
   ],
   "source": [
    "# Ruta al video generado con conteo\n",
    "video_path = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/Bogot√° traffic video_count.mp4\")\n",
    "gif_path   = video_path.with_suffix(\".gif\")\n",
    "\n",
    "# Capturar video con OpenCV\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "assert cap.isOpened(), f\"No se pudo abrir {video_path}\"\n",
    "\n",
    "# Extraer fps y duraci√≥n estimada\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "total  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "dur    = total / fps\n",
    "\n",
    "# Definir segmento (por ejemplo, del segundo 10 al 15)\n",
    "start_sec = 10\n",
    "end_sec   = 15\n",
    "start_f   = int(start_sec * fps)\n",
    "end_f     = int(end_sec * fps)\n",
    "\n",
    "frames = []\n",
    "i = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or i > end_f:\n",
    "        break\n",
    "    if i >= start_f:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_resized = cv2.resize(frame_rgb, (640, int(640 * frame.shape[0] / frame.shape[1])))\n",
    "        frames.append(frame_resized)\n",
    "    i += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Escribir GIF\n",
    "imageio.mimsave(str(gif_path), frames, fps=10, loop=0)\n",
    "print(f\"‚úÖ GIF creado en: {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéûÔ∏è  FPS: 30.00 | Frames totales: 9184\n",
      "‚úÖ Imagen guardada: /home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/4K Road traffic video_count_frame400.png\n"
     ]
    }
   ],
   "source": [
    "# Ruta al video de salida\n",
    "video_path = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/4K Road traffic video_count.mp4\")\n",
    "output_dir = video_path.parent\n",
    "\n",
    "# Frame que quieres capturar (por ejemplo, el n√∫mero 400)\n",
    "frame_to_capture = 400\n",
    "save_path = output_dir / f\"{video_path.stem}_frame{frame_to_capture}.png\"\n",
    "\n",
    "# Abrir video\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "assert cap.isOpened(), f\"No se pudo abrir {video_path}\"\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"üéûÔ∏è  FPS: {fps:.2f} | Frames totales: {total_frames}\")\n",
    "\n",
    "# Capturar el frame espec√≠fico\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_to_capture)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    cv2.imwrite(str(save_path), frame)\n",
    "    print(f\"‚úÖ Imagen guardada: {save_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå No se pudo capturar el frame {frame_to_capture}\")\n",
    "\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
