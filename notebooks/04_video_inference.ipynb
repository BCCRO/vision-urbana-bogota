{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce5134f",
   "metadata": {},
   "source": [
    "# üé• **04-Inferencia de Video con YOLO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b284f",
   "metadata": {},
   "source": [
    "Este notebook aplica un modelo YOLO entrenado (o pre-entrenado) para detectar y contar veh√≠culos en un video, guardar la secuencia anotada y reportar m√©tricas de rendimiento (FPS, latencia, tiempo total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cc0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac81ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video de entrada \n",
    "VIDEO_IN = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/data/test/4K Road traffic video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ddf301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos del modelo YOLO entrenado \n",
    "MODEL_PT = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/models/yolov10m/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67059557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caperta de salida para los resultados\n",
    "OUTPUT_DIR = Path(\"/home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b607f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video de salida con las detecciones\n",
    "VIDEO_OUT = OUTPUT_DIR / f\"{VIDEO_IN.stem}_yolo.mp4\"\n",
    "# Otros par√°metros\n",
    "IMG_SIZE = 640\n",
    "CONF_THRESH = 0.25\n",
    "DEVICE = 0            # 0 ‚Üí GPU 0,  \n",
    "SHOW_FRAMES = False   # True para ver frames en tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2053a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10m summary (fused): 369 layers, 16,451,542 parameters, 0 gradients, 63.4 GFLOPs\n",
      "Modelo best.pt\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(str(MODEL_PT))\n",
    "model.fuse()  # acelera inferencia\n",
    "print(f\"Modelo {MODEL_PT.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b325a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resoluci√≥n: 1920√ó1080  |  FPS original: 30.00\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(str(VIDEO_IN))\n",
    "assert cap.isOpened(), f\"No se pudo abrir {VIDEO_IN}\"\n",
    "\n",
    "# Propiedades del video\n",
    "fps_in  = cap.get(cv2.CAP_PROP_FPS)\n",
    "width   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Resoluci√≥n: {width}√ó{height}  |  FPS original: {fps_in:.2f}\")\n",
    "\n",
    "# üé• VideoWriter para guardar la salida\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") # type: ignore\n",
    "writer = cv2.VideoWriter(str(VIDEO_OUT), fourcc, fps_in, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1925088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Inferencia y escritura de frames\n",
    "frame_count, t0 = 0, time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Inferencia\n",
    "    res = model.predict(\n",
    "        frame,\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=CONF_THRESH,\n",
    "        device=DEVICE,\n",
    "        stream=False,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    # Dibujar resultados sobre el frame\n",
    "    annotated = res.plot()\n",
    "\n",
    "    # Escribir frame anotado\n",
    "    writer.write(annotated)\n",
    "\n",
    "    # Mostrar en pantalla opcional\n",
    "    if SHOW_FRAMES:\n",
    "        cv2.imshow(\"YOLO Inference\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:   # ESC para salir\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "t_total = time.time() - t0\n",
    "cap.release()\n",
    "writer.release()\n",
    "if SHOW_FRAMES:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c441dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà  Frames procesados : 9184\n",
      "‚è±Ô∏è  Tiempo total      : 126.31 s\n",
      "‚ö° FPS promedio       : 72.71\n",
      "‚åõ Latencia promedio  : 13.75 ms por frame\n",
      "üéûÔ∏è  Video guardado en : /home/guardiaserver/bogota/vision-urbana-bogota/results/video_inference/4K Road traffic video_yolo.mp4\n"
     ]
    }
   ],
   "source": [
    "fps_real = frame_count / t_total\n",
    "lat_ms   = 1000 * t_total / frame_count\n",
    "\n",
    "print(f\"üìà  Frames procesados : {frame_count}\")\n",
    "print(f\"‚è±Ô∏è  Tiempo total      : {t_total:.2f} s\")\n",
    "print(f\"‚ö° FPS promedio       : {fps_real:.2f}\")\n",
    "print(f\"‚åõ Latencia promedio  : {lat_ms:.2f} ms por frame\")\n",
    "print(f\"üéûÔ∏è  Video guardado en : {VIDEO_OUT}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
